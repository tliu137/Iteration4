{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/ubuntu/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('BDAS').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "schema = StructType([\n",
    "               StructField('month',IntegerType(),True),\n",
    "               StructField('SO2',FloatType(),True),\n",
    "               StructField('NO2',FloatType(),True),\n",
    "               StructField('CO',FloatType(),True),\n",
    "               StructField('O3',FloatType(),True),\n",
    "               StructField('TEMP',FloatType(),True),\n",
    "               StructField('PRES',FloatType(),True),\n",
    "               StructField('DewPointTempeature',FloatType(),True),\n",
    "               StructField('WindSpend',FloatType(),True),\n",
    "               StructField('WindDirectionIndex',DoubleType(),True),\n",
    "               StructField('stationIndex',DoubleType(),True),\n",
    "               StructField('NQRIndex',DoubleType(),True),\n",
    "               StructField('SeasonIndex',DoubleType(),True),\n",
    "                ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = spark.read.format(\"csv\") \\\n",
    "      .option(\"header\", True) \\\n",
    "      .schema(schema) \\\n",
    "      .load(\"../final_dataset/after_feature.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----+-----+------+----+----+------+------------------+---------+------------------+------------+-----------+--------+\n",
      "|month| SO2|  NO2|    CO|  O3|TEMP|  PRES|DewPointTempeature|WindSpend|WindDirectionIndex|stationIndex|SeasonIndex|NQRIndex|\n",
      "+-----+----+-----+------+----+----+------+------------------+---------+------------------+------------+-----------+--------+\n",
      "|    1|10.0| 16.0| 400.0|54.0|-1.0|1027.0|             -23.0|      0.9|               1.0|         4.0|        0.0|     0.0|\n",
      "|    1|11.0| 17.0| 400.0|53.0| 0.0|1025.0|             -22.9|      2.7|               1.0|         4.0|        0.0|     0.0|\n",
      "|    1|10.0| 15.0| 400.0|55.0| 0.0|1027.0|             -22.9|      2.4|               1.0|         4.0|        0.0|     0.0|\n",
      "|    1|13.0| 13.0| 400.0|57.0| 0.0|1028.0|             -24.4|      2.4|               1.0|         4.0|        0.0|     0.0|\n",
      "|    1|15.0| 12.0| 400.0|58.0| 0.0|1030.0|             -24.4|      2.4|               1.0|         4.0|        0.0|     0.0|\n",
      "|    1|13.0| 15.0| 500.0|55.0|-1.0|1024.0|             -24.4|      3.2|               9.0|         4.0|        0.0|     0.0|\n",
      "|    1|10.0| 30.0| 500.0|39.0|-4.0|1029.0|             -24.3|      0.9|              15.0|         4.0|        0.0|     0.0|\n",
      "|    1|10.0| 41.0| 600.0|30.0|-2.0|1029.0|             -23.9|      4.2|               9.0|         4.0|        0.0|     0.0|\n",
      "|    1|10.0| 55.0| 600.0|16.0|-2.0|1027.0|             -23.9|      1.9|               9.0|         4.0|        0.0|     0.0|\n",
      "|    1|11.0| 56.0| 600.0|17.0|-1.0|1026.0|             -23.0|      1.5|              10.0|         4.0|        0.0|     0.0|\n",
      "|    1|15.0| 56.0| 900.0|21.0| 0.0|1025.0|             -22.9|      2.1|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|26.0| 64.0|1300.0|23.0| 1.0|1029.0|             -22.8|      1.4|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|42.0| 76.0|1700.0|27.0| 1.0|1025.0|             -22.8|      2.5|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|37.0| 70.0|1500.0|37.0| 2.0|1025.0|             -22.8|      1.8|              10.0|         4.0|        0.0|     1.0|\n",
      "|    1|29.0| 59.0|1300.0|49.0| 3.0|1022.0|             -22.8|      2.0|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|18.0| 33.0| 900.0|64.0| 3.0|1020.0|             -22.8|      2.4|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|19.0| 39.0|1000.0|60.0| 3.0|1020.0|             -22.0|      2.7|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|23.0| 58.0|1300.0|46.0| 1.0|1021.0|             -22.1|      1.1|               4.0|         4.0|        0.0|     0.0|\n",
      "|    1|35.0| 89.0|1800.0|25.0|-1.0|1017.0|             -20.1|      1.2|              10.0|         4.0|        0.0|     1.0|\n",
      "|    1|43.0|106.0|2000.0|11.0|-2.0|1021.0|             -19.9|      1.1|              15.0|         4.0|        0.0|     1.0|\n",
      "+-----+----+-----+------+----+----+------+------------------+---------+------------------+------------+-----------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "column_list = file.columns\n",
    "last = column_list[-1]\n",
    "second_last = column_list[-2]\n",
    "column_list[-1]=second_last\n",
    "column_list[-2] = last\n",
    "file = file.select(*column_list)\n",
    "file.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import RFormula\n",
    "formula = RFormula(\n",
    "    formula=\"NQRIndex ~ .\",\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\")\n",
    "\n",
    "output = formula.fit(file).transform(file)\n",
    "vectorformat2 = output.select(\"features\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[1.0,10.0,16.0,40...|  0.0|\n",
      "|[1.0,11.0,17.0,40...|  0.0|\n",
      "|[1.0,10.0,15.0,40...|  0.0|\n",
      "|[1.0,13.0,13.0,40...|  0.0|\n",
      "|[1.0,15.0,12.0,40...|  0.0|\n",
      "|[1.0,13.0,15.0,50...|  0.0|\n",
      "|[1.0,10.0,30.0,50...|  0.0|\n",
      "|[1.0,10.0,41.0,60...|  0.0|\n",
      "|[1.0,10.0,55.0,60...|  0.0|\n",
      "|[1.0,11.0,56.0,60...|  0.0|\n",
      "|[1.0,15.0,56.0,90...|  0.0|\n",
      "|[1.0,26.0,64.0,13...|  0.0|\n",
      "|[1.0,42.0,76.0,17...|  0.0|\n",
      "|[1.0,37.0,70.0,15...|  1.0|\n",
      "|[1.0,29.0,59.0,13...|  0.0|\n",
      "|[1.0,18.0,33.0,90...|  0.0|\n",
      "|[1.0,19.0,39.0,10...|  0.0|\n",
      "|[1.0,23.0,58.0,13...|  0.0|\n",
      "|[1.0,35.0,89.0,18...|  1.0|\n",
      "|[1.0,43.0,106.0,2...|  1.0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "vectorformat2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import (RandomForestClassifier, GBTClassifier, DecisionTreeClassifier)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData, testData) = vectorformat2.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|            features|label|       rawPrediction|         probability|prediction|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "|[1.0,1.0,8.0,200....|  0.0|[19.9773576729089...|[0.99886788364544...|       0.0|\n",
      "|[1.0,1.0,12.0,200...|  0.0|[19.8467773747752...|[0.99233886873876...|       0.0|\n",
      "|[1.0,1.0,25.0,300...|  0.0|[19.9461311375264...|[0.99730655687632...|       0.0|\n",
      "|[1.0,1.0,62.0,100...|  0.0|[14.5857256100710...|[0.72928628050355...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9534910945276...|[0.99767455472638...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9954166472843...|[0.99977083236421...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9863218983185...|[0.99931609491592...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9954166472843...|[0.99977083236421...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9940697979656...|[0.99970348989828...|       0.0|\n",
      "|[1.0,2.0,2.0,100....|  0.0|[19.9331581478408...|[0.99665790739204...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9644662027813...|[0.99822331013906...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9918851788642...|[0.99959425894321...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9839442803002...|[0.99919721401501...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.5021236800588...|[0.97510618400294...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9869809441681...|[0.99934904720840...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9977875880917...|[0.99988937940458...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9200528313916...|[0.99600264156958...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.9872390564157...|[0.99936195282078...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.8111872513378...|[0.99055936256689...|       0.0|\n",
      "|[1.0,2.0,2.0,200....|  0.0|[19.8651735272709...|[0.99325867636354...|       0.0|\n",
      "+--------------------+-----+--------------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RunTime 58.44966220855713 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\",maxDepth=15)\n",
    "model_rf = rf.fit(trainingData)\n",
    "prediction_rf = model_rf.transform(testData)\n",
    "prediction_rf.show()\n",
    "print(\"RunTime %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassificationModel (uid=rfc_53222bad3ebb) with 20 trees\n"
     ]
    }
   ],
   "source": [
    "print(model_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aaccuracy =  81.28332300061997\n",
      "F1 score =  81.11866016641761\n",
      "Test Error = 0.187167\n"
     ]
    }
   ],
   "source": [
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "evaluatorf1 = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"f1\")\n",
    "accuracy = evaluator_accuracy.evaluate(prediction_rf)\n",
    "f1_score = evaluatorf1.evaluate(prediction_rf)\n",
    "print(\"Aaccuracy = \", accuracy*100)\n",
    "print(\"F1 score = \", f1_score*100)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model_rf.toDebugString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'O3': 0.0668266836867723, 'DewPointTempeature': 0.10704676056369415, 'PRES': 0.05616735722740879, 'WindSpend': 0.04127716161236746, 'SO2': 0.12042320123552756, 'stationIndex': 0.031337918707861595, 'WindDirectionIndex': 0.030110974780392485, 'SeasonIndex': 0.0, 'TEMP': 0.0506734871577071, 'CO': 0.30375581048892475, 'month': 0.054599338931692956, 'NO2': 0.13778130560765084}\n"
     ]
    }
   ],
   "source": [
    "ff = model_rf.featureImportances\n",
    "importancesList=[float(col) for col in  ff]\n",
    "colList = file.columns\n",
    "result=dict(zip(colList,importancesList))\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
